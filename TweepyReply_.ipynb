{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TweepyReply .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1dpnVoUxNoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Joshua Alvarado\n",
        "#06/06/2020\n",
        "#Josh.alvarado0328@gmail.com\n",
        "\n",
        "#Import the libraries\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Twitter Api Credentials\n",
        "\n",
        "Consumer_Key = \"xxx\"\n",
        "\n",
        "Consumer_Secret_Key = \"xxx\"\n",
        "\n",
        "Access_Token = \"xxx\"\n",
        "\n",
        "Access_Token_Secret = \"xxx\"\n",
        "\n",
        "#uthenticating Keys\n",
        "\n",
        "auth = tweepy.OAuthHandler(Consumer_Key,Consumer_Secret_Key)\n",
        "\n",
        "auth.set_access_token(Access_Token,Access_Token_Secret)\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit= True,parser=tweepy.parsers.JSONParser())\n",
        "\n",
        "#Target term which is the the bot @name\n",
        "target_term=\"@FindSentiment\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-S2Su12xNr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_visuals(handle):\n",
        "    #Extract 100 tweets from user\n",
        "    posts = api.user_timeline(screen_name=handle, count=100, lang= \"en\",tweet_mode=\"extended\")\n",
        "    #Print last 5 recent tweets\n",
        "    print(\"Show the 5 recent tweets: \\n\")\n",
        "    i=1\n",
        "    for tweet in posts[0:5]:\n",
        "      print(str(i)+') ' + tweet[\"full_text\"] + \"\\n\")\n",
        "      i = i + 1\n",
        "\n",
        "    #Create a dataframe with a columb called tweets\n",
        "    df = pd.DataFrame( [tweet[\"full_text\"] for tweet in posts], columns=['tweets'])\n",
        "\n",
        "    #show the first 5 rows of data\n",
        "    df.head()\n",
        "\n",
        "    #Clean the text\n",
        "\n",
        "    #Create a function to clean the tweets\n",
        "    def cleanTxt(text):\n",
        "      text = re.sub(r'@[\\w:]+', '', text) #removes @mentions\n",
        "      text = re.sub(r'#','',text) #removing # symbol\n",
        "      text = re.sub(r'RT[\\s]+','',text) #removes retweets\n",
        "      text = re.sub(r'https?:\\/\\/\\S+','', text) #remove hyperlinks\n",
        "      return text\n",
        "\n",
        "    df['tweets'] = df['tweets'].apply(cleanTxt)\n",
        "\n",
        "    #Show the cleaned text\n",
        "    df\n",
        "\n",
        "    # Create a function to get the subjectivity\n",
        "    def getSubjectivity(text):\n",
        "      return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "    # Create a function to get the polarity\n",
        "    def getPolarity(text):\n",
        "      return TextBlob(text).sentiment.polarity\n",
        "\n",
        "    # Create two new columns\n",
        "    df['Subjectivity'] = df['tweets'].apply(getSubjectivity)\n",
        "    df['Polarity'] = df['tweets'].apply(getPolarity)\n",
        "\n",
        "    # Show the new dataframe with the new columns\n",
        "\n",
        "    # Plot the Word Cloud\n",
        "\n",
        "    allWords = ' '.join([twts for twts in df ['tweets']])\n",
        "    wordCloud = WordCloud(width = 500, height = 300, random_state = 21, max_font_size=119,).generate(allWords)\n",
        "\n",
        "    plt.imshow(wordCloud, interpolation = \"bilinear\")\n",
        "    plt.axis('off')\n",
        "    plt.title('Most common words for @' + handle)\n",
        "    plt.savefig('wordcloud.png',bbox_inches='tight',dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "    #Create a function to compute the negative, neutral and positive analysis\n",
        "    def getAnalysis(score):\n",
        "      if score < 0:\n",
        "        return 'Negative'\n",
        "      elif score == 0:\n",
        "        return 'Neutral'\n",
        "      else:\n",
        "        return 'Positive'\n",
        "\n",
        "    df['Analysis'] = df['Polarity'].apply(getAnalysis)\n",
        "\n",
        "    df\n",
        "\n",
        "    # Print all of the positive tweets\n",
        "    j=1\n",
        "    sortedDF = df.sort_values(by=['Polarity'])\n",
        "    for i in range (0, sortedDF.shape[0]):\n",
        "      if(sortedDF['Analysis'][i] == 'Neutral'):\n",
        "        print(str(j) + ')' + sortedDF['tweets'][i])\n",
        "        print()\n",
        "        j = j+1\n",
        "\n",
        "    # Print negative tweets\n",
        "    j=1\n",
        "    sortedDF = df.sort_values(by=['Polarity'], ascending='False')\n",
        "    for i in range (0, sortedDF.shape[0]):\n",
        "      if( sortedDF['Analysis'][i] == 'Negative'):\n",
        "        print(str(j) + ')' + sortedDF['tweets'][i])\n",
        "        print()\n",
        "        j = j+1\n",
        "\n",
        "    # Plot the polarity and subjectivity \n",
        "    plt.figure(figsize=(8,6))\n",
        "    for i in range(0, df.shape[0]):\n",
        "      plt.scatter(df['Polarity'][i],df['Subjectivity'][i], color='blue')\n",
        "      \n",
        "    plt.title('Sentiment Analysis for @' + handle)\n",
        "    plt.xlabel('Polarity')\n",
        "    plt.ylabel('Subjectivity')\n",
        "    plt.savefig('plot.png',bbox_inches='tight',dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "    # Get the percentage of positive tweets \n",
        "\n",
        "    ptweets = df[df.Analysis == 'Positive']\n",
        "    ptweets = ptweets['tweets']\n",
        "\n",
        "    round( (ptweets.shape[0] / df.shape[0]) *100, 1)\n",
        "\n",
        "    # Get the percentage of negative tweets \n",
        "\n",
        "    ntweets = df[df.Analysis == 'Negative']\n",
        "    ntweets = ntweets['tweets']\n",
        "\n",
        "    round( (ntweets.shape[0] / df.shape[0]) *100, 1)\n",
        "\n",
        "    # Get the percentage of negative tweets \n",
        "\n",
        "    Neutraltweets = df[df.Analysis == 'Neutral']\n",
        "    Neutraltweets = Neutraltweets['tweets']\n",
        "\n",
        "    round( (Neutraltweets.shape[0] / df.shape[0]) *100, 1)\n",
        "\n",
        "    # show the value counts\n",
        "\n",
        "    df['Analysis'].value_counts()\n",
        "\n",
        "    # plot and visualize the counts\n",
        "\n",
        "    plt.title('Sentiment Analysis for @' + handle)\n",
        "    plt.xlabel('Sentment')\n",
        "    plt.ylabel('Counts')\n",
        "    df['Analysis'].value_counts().plot(kind='bar')\n",
        "    plt.savefig('graph.png',bbox_inches='tight',dpi=600)\n",
        "    plt.show()\n",
        "\n",
        "    # images = ('graph.png', 'wordcloud.png','plot.png')\n",
        "    # test = [api.media_upload(i) for i in images]\n",
        "    # print(test)\n",
        "    # media_ids = [api.media_upload(i)['media_id_string'] for i in images]\n",
        "    # print(\"I should have images \")\n",
        "    # api.update_status(\n",
        "    #                 \"@%s thank you for using FindSentiment! Heres your data!\" %\n",
        "    #                 handle, media_ids=media_ids,\n",
        "    #                 in_reply_to_status_id=tweet_id)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZs_x1fuzUpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def start(): \n",
        "  public_tweets = api.search(target_term, count=5, result_type=\"recent\")\n",
        "  for tweet in public_tweets[\"statuses\"]:\n",
        "    print(\"We are in here\")\n",
        "  # Get ID and Author of most recent tweet directed to me\n",
        "    tweet_id = tweet[\"id\"]\n",
        "    handle = tweet[\"user\"][\"screen_name\"] \n",
        "    print(handle)\n",
        "    try:\n",
        "      create_visuals(handle)\n",
        "      images = ('graph.png', 'wordcloud.png','plot.png')\n",
        "      test = [api.media_upload(i) for i in images]\n",
        "      print(test)\n",
        "      media_ids = [api.media_upload(i)['media_id_string'] for i in images]\n",
        "      print(\"I should have images \")\n",
        "      api.update_status(\n",
        "                      \"@%s thank you for using FindSentiment! Heres your data!\" %\n",
        "                      handle, media_ids=media_ids,\n",
        "                      in_reply_to_status_id=tweet_id)\n",
        "      print(\"WE DID IT SUCCESS!\")\n",
        "    except Exception:\n",
        "      print(\"We've already replied to this.\")\n",
        "      raise\n",
        "    print(\"We're done for now. I'll check again in 60 seconds.\")\n",
        "\n",
        "while(True):\n",
        "  start()\n",
        "  time.sleep(60)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
